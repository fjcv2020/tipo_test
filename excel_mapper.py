#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excel Mapper
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Lee un PDF de preguntas y otro de respuestas + aclaraciones y genera OUTPUT.xlsx
con las 18 columnas de la plantilla, manteniendo la literalidad de todos los textos.

Ejemplo de uso
--------------
python excel_mapper.py --preguntas "Test n¬∫2 T11.pdf" \
                       --respuestas "Test n¬∫2 T11_Tabla.pdf" \
                       --tema 11
"""

import argparse
import re
from pathlib import Path
import os
from dotenv import load_dotenv
from openai import OpenAI
import json

import fitz  # PyMuPDF
import pandas as pd

# Cargar la clave de OpenAI
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=openai_api_key)

# =========================
# 1) utilidades
# =========================
def extraer_texto(ruta_pdf: Path) -> str:
    """Devuelve todo el texto del PDF con saltos de l√≠nea preservados."""
    doc = fitz.open(ruta_pdf)
    return "\n".join(p.get_text(sort=True) for p in doc)  # sort=True ‚Üí orden natural

def normalizar_saltos(texto: str) -> str:
    """Unifica saltos de l√≠nea \r\n / \r / \n en solo \n."""
    return texto.replace("\r\n", "\n").replace("\r", "\n")

# =========================
# 2) parsing de preguntas
# =========================
def obtener_preguntas(texto_preguntas: str):
    """
    Devuelve lista de tuplas:
      (n¬∫, enunciado, A, B, C, D)
    Literalidad absoluta, tolerando saltos de l√≠nea en enunciado y opciones.
    """
    lineas = [l.rstrip() for l in texto_preguntas.splitlines()]
    preguntas = []
    i = 0
    while i < len(lineas):
        # Buscar inicio de pregunta: n√∫mero punto espacio
        if lineas[i].strip().startswith(tuple(str(n)+'.' for n in range(1, 101))):
            num_match = re.match(r'^(\d{1,3})\.\s*(.*)', lineas[i].strip())
            if not num_match:
                i += 1
                continue
            num = int(num_match.group(1))
            enunciado = num_match.group(2)
            i += 1
            # Acumular l√≠neas de enunciado hasta encontrar 'a)'
            while i < len(lineas) and not re.match(r'^[aA]\)', lineas[i].strip()):
                if lineas[i].strip():  # Solo agregar l√≠neas no vac√≠as
                    enunciado += (' ' if enunciado else '') + lineas[i].strip()
                i += 1
            # Limpiar espacios extra del enunciado
            enunciado = re.sub(r'\s+', ' ', enunciado.strip())
            # Acumular opciones
            opciones = {}
            for letra in ['A', 'B', 'C', 'D']:
                opcion = ''
                if i < len(lineas) and re.match(rf'^{letra.lower()}\)', lineas[i].strip(), re.IGNORECASE):
                    op_match = re.match(rf'^{letra.lower()}\)\s*(.*)', lineas[i].strip(), re.IGNORECASE)
                    opcion = op_match.group(1) if op_match else ''
                    i += 1
                    while i < len(lineas):
                        # Si la siguiente l√≠nea es otra opci√≥n o una nueva pregunta, paramos
                        if any(re.match(rf'^{l.lower()}\)', lineas[i].strip(), re.IGNORECASE) for l in ['A','B','C','D'] if l != letra):
                            break
                        if re.match(r'^(\d{1,3})\.\s*', lineas[i].strip()):
                            break
                        if lineas[i].strip():  # Solo agregar l√≠neas no vac√≠as
                            opcion += ' ' + lineas[i].strip()
                        i += 1
                    # Limpiar espacios extra de la opci√≥n
                    opcion = re.sub(r'\s+', ' ', opcion.strip())
                opciones[letra] = opcion
            if all(k in opciones for k in ['A','B','C','D']):
                preguntas.append((num, enunciado, opciones['A'], opciones['B'], opciones['C'], opciones['D']))
        else:
            i += 1
    return preguntas

# =========================
# 3) parsing de respuestas
# =========================
def obtener_respuestas(texto_respuestas: str):
    """
    Devuelve dos diccionarios:
      respuestas[num]    -> 'A'-'F'
      aclaraciones[num]  -> texto completo
    """
    lineas = [l.rstrip() for l in texto_respuestas.splitlines()]
    respuestas, aclaraciones = {}, {}
    patron = re.compile(r'(\b(\d{1,2})\s+([A-F])\b)')
    bloques = []
    bloque = []
    for l in lineas:
        if patron.search(l):
            if bloque:
                bloques.append(bloque)
            bloque = [l]
        else:
            bloque.append(l)
    if bloque:
        bloques.append(bloque)
    for b in bloques:
        # Buscar n√∫mero y letra
        m = patron.search(b[0])
        if m:
            n = int(m.group(2))
            letra = m.group(3)
            respuestas[n] = letra
            # La aclaraci√≥n es todo el bloque menos la primera l√≠nea
            aclaraciones[n] = "\n".join(b[1:]).strip()
    return respuestas, aclaraciones

# =========================
# LLM para extraer todas las aclaraciones
# =========================

def extraer_todas_aclaraciones_llm(texto_pdf_respuestas, lista_preguntas):
    """Una sola llamada al LLM para extraer todas las aclaraciones en formato JSON."""
    numeros_preguntas = [str(p[0]) for p in lista_preguntas]
    
    # Prompt mejorado para capturar aclaraciones completas (antes + despu√©s del patr√≥n)
    prompt = f"""
Extrae las aclaraciones del PDF de respuestas de examen. Devuelve SOLO un JSON v√°lido:

{{"1": "aclaraci√≥n pregunta 1", "2": "aclaraci√≥n pregunta 2", ...}}

INSTRUCCIONES CR√çTICAS:
- Busca el patr√≥n: "N√öMERO + ESPACIOS + LETRA" (ej: "1      D", "2      B")
- La aclaraci√≥n de cada pregunta est√° DIVIDIDA en dos partes:
  * ANTES del patr√≥n: texto que pertenece a esa pregunta
  * DESPU√âS del patr√≥n: continuaci√≥n del texto hasta la siguiente pregunta
- Combina AMBAS partes para formar la aclaraci√≥n completa
- LIMPIA EL FORMATO: elimina espacios extra, tabulaciones y saltos de l√≠nea innecesarios
- Convierte m√∫ltiples espacios en uno solo
- Mant√©n solo los saltos de l√≠nea necesarios para la estructura del texto
- Copia literal el CONTENIDO pero con formato limpio
- Si no hay aclaraci√≥n, usa ""
- Solo JSON, sin texto extra

EJEMPLO DEL PATR√ìN REAL:
```
Art. 12 Ley 45/2015 "El acuerdo de incorporaci√≥n...  ‚Üê PARTE 1 (antes)
     1      D                                        ‚Üê PATR√ìN
se requiera para el cumplimiento...convenido."       ‚Üê PARTE 2 (despu√©s)
```
La aclaraci√≥n completa = PARTE 1 + PARTE 2 (con formato limpio)

Preguntas a procesar: {', '.join(numeros_preguntas[:10])}...{', '.join(numeros_preguntas[-5:])}

PDF:
{texto_pdf_respuestas[:80000]}"""

    try:
        respuesta = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=16000,
            temperature=0.0,
        )
        
        contenido = respuesta.choices[0].message.content.strip()
        print(f"[LLM] Respuesta recibida: {len(contenido)} caracteres")
        
        # GUARDAR LA RESPUESTA DEL LLM PARA AN√ÅLISIS
        with open("respuesta_llm.txt", "w", encoding="utf-8") as f:
            f.write("=== PROMPT ENVIADO ===\n")
            f.write(prompt)
            f.write("\n\n=== RESPUESTA DEL LLM ===\n")
            f.write(contenido)
        print(f"[LLM] üíæ Respuesta guardada en respuesta_llm.txt")
        
        # Limpiar posibles caracteres extra antes/despu√©s del JSON
        if contenido.startswith('```'):
            contenido = contenido.split('```')[1]
        if contenido.startswith('json'):
            contenido = contenido[4:]
        contenido = contenido.strip()
        
        # Intentar parsear el JSON
        try:
            aclaraciones_json = json.loads(contenido)
            # Convertir claves a enteros
            resultado = {int(k): v for k, v in aclaraciones_json.items()}
            print(f"[LLM] ‚úÖ Extra√≠das {len(resultado)} aclaraciones")
            return resultado
        except json.JSONDecodeError as e:
            print(f"[LLM] ‚ùå Error parseando JSON: {e}")
            print(f"[LLM] Contenido: {contenido[:500]}...")
            return {}
            
    except Exception as e:
        print(f"[LLM] ‚ùå Error: {e}")
        return {}

# =========================
# 4) construcci√≥n del Excel
# =========================
COLUMNAS = [
    "Id pregunta para imagen",
    "Enunciado pregunta",
    "Texto respuesta A",
    "Texto respuesta B",
    "Texto respuesta C",
    "Texto respuesta D",
    "Texto respuesta E",
    "Texto respuesta F",
    "Respuesta correcta",
    "N¬∫ Tema",
    "Nombre Tema",
    "Nombre de subtema",
    "Nombre del apartado",
    "Etiqueta",
    "Tipo Tema (T o P)",
    "Aclaraci√≥n respuesta",
    "Estado",
    "Contexto de aclaraci√≥n",
]

def generar_excel(pregs, resps, aclas, tema_num, texto_pdf_respuestas):
    # Una sola llamada al LLM para todas las aclaraciones
    aclaraciones_llm = extraer_todas_aclaraciones_llm(texto_pdf_respuestas, pregs)
    
    filas = []
    for (num, enunciado, a, b, c, d) in pregs:
        aclaracion = aclaraciones_llm.get(num, "")
        if not aclaracion:  # Si est√° vac√≠a, intentar con string
            aclaracion = aclaraciones_llm.get(str(num), "")
        
        filas.append({
            "Id pregunta para imagen": num,
            "Enunciado pregunta": enunciado,
            "Texto respuesta A": a,
            "Texto respuesta B": b,
            "Texto respuesta C": c,
            "Texto respuesta D": d,
            "Texto respuesta E": "",
            "Texto respuesta F": "",
            "Respuesta correcta": resps.get(num, ""),
            "N¬∫ Tema": tema_num or "",
            "Nombre Tema": "",
            "Nombre de subtema": "",
            "Nombre del apartado": "",
            "Etiqueta": "",
            "Tipo Tema (T o P)": "",
            "Aclaraci√≥n respuesta": aclaracion if aclaracion else None,
            "Estado": "Publicada",
            "Contexto de aclaraci√≥n": "",
        })
    df = pd.DataFrame(filas, columns=COLUMNAS)
    df.to_excel("OUTPUT.xlsx", index=False, engine="openpyxl")
    print("‚úÖ OUTPUT.xlsx generado con √©xito.")

# =========================
# 5) CLI
# =========================
def main():
    parser = argparse.ArgumentParser(description="Genera OUTPUT.xlsx a partir de 2 PDFs.")
    parser.add_argument("--preguntas", required=True, help="Ruta al PDF de preguntas")
    parser.add_argument("--respuestas", required=True, help="Ruta al PDF de respuestas + aclaraciones")
    parser.add_argument("--tema", help="N√∫mero de Tema (opcional)")
    args = parser.parse_args()

    # 1) leer PDFs
    texto_p = normalizar_saltos(extraer_texto(Path(args.preguntas)))
    texto_r = normalizar_saltos(extraer_texto(Path(args.respuestas)))

    # DEBUG: mostrar las primeras 40 l√≠neas del texto de respuestas extra√≠do
    print("--- Primeras 40 l√≠neas del PDF de respuestas extra√≠do ---")
    for idx, l in enumerate(texto_r.splitlines()[:40]):
        print(f"{idx+1:02d}: {repr(l)}")
    print("----------------------------------------------------------")

    # 2) parsear
    preguntas = obtener_preguntas(texto_p)
    respuestas, aclaraciones = obtener_respuestas(texto_r)

    # DEBUG: mostrar los n√∫meros de pregunta y respuestas detectados
    print("N√∫meros de pregunta extra√≠dos:", [p[0] for p in preguntas])
    print("N√∫meros de respuesta extra√≠dos:", list(respuestas.keys()))
    if respuestas:
        k = list(respuestas.keys())[0]
        print(f"Ejemplo respuesta: {k} -> {respuestas[k]}")
        print(f"Ejemplo aclaraci√≥n: {k} -> {aclaraciones[k][:100]}...")

    # 3) construir Excel
    generar_excel(preguntas, respuestas, aclaraciones, args.tema, texto_r)

if __name__ == "__main__":
    main() 